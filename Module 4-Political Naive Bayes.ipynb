{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sqlite3\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "np.int = np.int_\n",
    "np.float = np.float_\n",
    "import nltk\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, download the stopwords.zip file from https://www.nltk.org/nltk_data/ and then extract it\n",
    "source_dir = '/Users/calebmccurdy/downloads/stopwords'\n",
    "dest_dir = '/Users/calebmccurdy/nltk_data/corpora/stopwords'\n",
    "\n",
    "if os.path.exists(dest_dir):\n",
    "    shutil.rmtree(dest_dir)\n",
    "shutil.move(source_dir, dest_dir)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison\n",
    "\n",
    "# Albrecht, J., Ramachandran, S., & Winkler, C. (2020). Blueprints for text analytics using Python. O'Reilly. \n",
    "RE_TOKEN = re.compile(r\"\"\"\n",
    "               ( [#]?[@\\w'’\\.\\-\\:]*\\w     # words, hash tags and email adresses\n",
    "               | [:;<]\\-?[\\)\\(3]          # coarse pattern for basic text emojis\n",
    "               | [\\U0001F100-\\U0001FFFF]  # coarse code range for unicode emojis\n",
    "               )\n",
    "               \"\"\", re.VERBOSE)\n",
    "\n",
    "def clean_tokenize(text):\n",
    "    # remove punctuation characters\n",
    "    text = ''.join([char for char in text if char not in punctuation])\n",
    "    # fold to lowercase\n",
    "    text = text.lower()\n",
    "    # remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word.lower() not in sw])\n",
    "    # remove extra white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # strip the text\n",
    "    text = text.strip()\n",
    "    return(text)\n",
    "    # could use this if we wanted to tokenize now\n",
    "    # return RE_TOKEN.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\"SELECT * FROM conventions\")\n",
    "\n",
    "\n",
    "for row in query_results :\n",
    "    text = row[5]  # convention text is in the 6th column\n",
    "    party = row[0]  # political party is in the 1st column\n",
    "\n",
    "    # Preprocess the text using the clean_tokenize function\n",
    "    cleaned_text = clean_tokenize(text)\n",
    "\n",
    "    # Append tokenized_text and party as a sublist to convention_data\n",
    "    convention_data.append([cleaned_text, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['thanks bernie want thank joining us segment mean sincerely honor run there’s even greater honor stand support joe biden kamala harris',\n",
       "  'Democratic'],\n",
       " ['singing', 'Democratic'],\n",
       " ['thank mr president honor mine', 'Republican'],\n",
       " ['daughter’s murder media didn’t seem interested facts found learned gun control laws didn’t fail daughter people gunman threatened kill classmates threatened rape threatened shoot school every red flag could imagine school didn’t miss red flags knowingly ignored far left democrats school district made shooting possible implemented something called restorative justice policy really blames teachers student’s failures puts kids teachers risk make shootings likely built pioneering approach discipline safety fine old approach discipline safety called discipline safety obamabiden administration took parkland’s bad policies forced schools across america',\n",
       "  'Republican'],\n",
       " ['south bend feared best days behind us reimagined economy new jobs even new industries hoosier state ready lead america’s recovery diverse communities talented workers best world agriculture joe biden’s plan gives us blueprint revitalize industrial cities rural areas alike indiana casts 2 votes friend bernie sanders 86 votes next president joe biden',\n",
       "  'Democratic'],\n",
       " ['visiting parents grandparents window nursing home worrying time they’ll get sick',\n",
       "  'Democratic'],\n",
       " ['acting secretary wolf present five candidates naturalization representing five countries',\n",
       "  'Republican'],\n",
       " ['it’s rare quality bring empathy skills process governing joe biden never forgets that’s point moving wheels government',\n",
       "  'Democratic'],\n",
       " ['never allow mob rule strongest possible terms republican party condemns rioting looting arson violence seen democratrun cities like kenosha minneapolis portland chicago new york many others democrat run violence danger streets many democratrun cities throughout america problem could easily fixed wanted call we’re ready go we’ll take care problem matter hours call wait call it’s bad wait call must always law order federal crimes investigated prosecuted punished fullest extent law',\n",
       "  'Republican'],\n",
       " ['led joe biden it’s aimed ending disease killed vice president’s son 600000 americans every year',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the text into individual words\n",
    "    words = text.split()\n",
    "\n",
    "    # Create a dictionary to store feature words found in the text\n",
    "    ret_dict = {word: True for word in words if word in fw}\n",
    "\n",
    "    return (ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use assertions to test that the code is working as intended\n",
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Party: Democratic, Count: 308\n",
      "Party: Republican, Count: 192\n"
     ]
    }
   ],
   "source": [
    "test_party_counts = Counter(party for _, party in test_set)\n",
    "\n",
    "# Print the counts\n",
    "for party, count in test_party_counts.items():\n",
    "    print(f\"Party: {party}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Observations\n",
    "\n",
    "Of all the top 25 most informative features in the classifier, 23 of them strongly favor words appearing in a Republican convention. The only featured words with a high enough ratio in the other direction are \"votes\" and \"climate\". This could be a cause of the Republican party being more narrowly focused on what it deems as issues while the Democratic party is more broad in their approach. I believe this is likely to sway many of the predictions towards the Republican party when they should have instead been Democratic. This idea may be backed by the fact that the classifier only had an accuracy of 50% on the test despite the party breakdown being 60-40. Thus, a simple baseline model that predicts only Democratic would have even performed better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\"\"\"\n",
    "            SELECT DISTINCT \n",
    "                cd.candidate, \n",
    "                cd.party,\n",
    "                tw.tweet_text\n",
    "            FROM candidate_data cd \n",
    "            INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "                AND cd.candidate == tw.candidate \n",
    "                AND cd.district == tw.district\n",
    "            WHERE cd.party in ('Republican','Democratic') \n",
    "                AND tw.tweet_text NOT LIKE '%RT%'\n",
    "            \"\"\")\n",
    "\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "for row in results:\n",
    "    tweet_text = row[2]  # tweet text is in the 3rd column\n",
    "    party = row[1]  # political party is in the 2nd column\n",
    "\n",
    "    cleaned_tweet = clean_tokenize(tweet_text.decode('utf-8'))  # Decode the tweet text first, then tokenize\n",
    "\n",
    "    tweet_data.append([cleaned_tweet, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201015)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: icymi saturday joined recent graduates us merchant marine academy helped welcome aboard new group plebes grateful young men women answered call serve httpstcoevee3hhdfw\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: istand men women law enforcement sheriffclarke sheriffclarkchallenge 1000 ppl ×25maga httpstconluvnsv9km httpstcoc6vmgb1hvn\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: httptcoclphxnpdjx\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: sfljetsfanclub jetsfanclub see new fp mag piece nyjets player speaks extreme anti israel conf httptco0wesp7fwlx\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: simply put trump family separation policychild abuse long term detention military facilities new trump executive orderchild abuse\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: everyday policy personnel wh shows us exactly values priorities —this november let’s show yearofthewoman bluewave httpstcobmctaqmoql\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: clermont senior club hosted listening session community members could share thoughts represent httptcotfrgfrpwdt\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: looking fun safe halloween helpful safety tips txdps httpstcoafrr75zjcp\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: stand 2nd amendment rights sign petition today httpstcobotu9nqkyt httpstcovo6jfzwixu\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: proud endorsed aftkc represents educators across kansas city metro area together show repsamgraves washington hard working people like matter missourimatters httpstcos1l2igcoj6\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp\n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3801, 'Democratic': 613}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4723, 'Democratic': 865})})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets by political party:\n",
      "Party: Republican, Count: 288531, Percentage: 43.41%\n",
      "Party: Democratic, Count: 376125, Percentage: 56.59%\n"
     ]
    }
   ],
   "source": [
    "print(\"Total tweets by political party:\")\n",
    "tweet_party_counts = Counter(sublist[1] for sublist in tweet_data)\n",
    "total_instances = sum(tweet_party_counts.values())\n",
    "\n",
    "# Print the counts and percentage breakdown\n",
    "for party, count in tweet_party_counts.items():\n",
    "    percentage = (count / total_instances) * 100\n",
    "    print(f\"Party: {party}, Count: {count}, Percentage: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Party: Democratic, Average Word Count: 178.53\n",
      "Party: Republican, Average Word Count: 328.16\n"
     ]
    }
   ],
   "source": [
    "word_counts = defaultdict(list)\n",
    "\n",
    "# Calculate word counts for each text and store them by party\n",
    "for text, party in convention_data:\n",
    "    words = clean_tokenize(text)\n",
    "    word_counts[party].append(len(words))\n",
    "\n",
    "average_word_counts = {party: sum(counts) / len(counts) for party, counts in word_counts.items()}\n",
    "\n",
    "for party, average_count in average_word_counts.items():\n",
    "    print(f\"Party: {party}, Average Word Count: {average_count:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "As predicted in the previous section, our Naive Bayes classifier overpredicts the Republican class and underpredicts the Democratic one. Of the true Republican instances, 86.1% of the estimated classes were correct. However, the model also predicted 84.5% of the true Democratic tweets as being Republican. Overall, this is an accuracy score of only 46.65% which means that it does not perform well against an all-democratic baseline and even would not outperfrom a model that predicted the exact opposite results. Because of this imbalance, I also wanted to see how many words each party's convention text had to determine if this was part of the class imbalance prediction problem. As we can see, the average length of text for the Republican convention data was almost double that of the Democratic convention text which leads to larger featuring of words. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
